## Hiperparametre Optimizasyon MetodlarÄ± ( Hyperparameter Optimization Methods )

### GiriÅŸ
Hiperparametreler, makine Ã¶ÄŸrenimi modellerinin Ã¶ÄŸrenme sÃ¼recini kontrol eden ve doÄŸrudan modelin baÅŸarÄ±sÄ±nÄ± etkileyen ayarlardÄ±r. 
YanlÄ±ÅŸ veya varsayÄ±lan hiperparametrelerle eÄŸitilen bir model, dÃ¼ÅŸÃ¼k performans gÃ¶sterebilir ya da Ã¶nemli bir genelleme hatasÄ±na yol aÃ§abilir. 
Bu nedenle, modelin doÄŸruluÄŸunu ve genelleme yeteneÄŸini en Ã¼st dÃ¼zeye Ã§Ä±karmak iÃ§in hiperparametrelerin dikkatlice seÃ§ilmesi gerekir.

GridSearchCV, RandomizedSearchCV ve daha yeni yaklaÅŸÄ±mlar olan Bayesian Optimization, Tree-structured Parzen Estimator (TPE) gibi yÃ¶ntemler, hiperparametre optimizasyonunu sistematik ve etkili bir ÅŸekilde yapÄ±lmasÄ±na olanak tanÄ±r. 
Bu yÃ¶ntemler, manuel deneme yanÄ±lma sÃ¼recinin yerini alarak hem zaman kazandÄ±rÄ±r hem de daha iyi sonuÃ§lar elde etmemizi saÄŸlar. 

---

### 1. RandomizedSearchCV

###### Scikit-learn kÃ¼tÃ¼phanesinde bulunan ve hÄ±zlÄ± olmasÄ± dolayÄ±sÄ±yla GridSearchCV'ye alternatif olarak kullanÄ±lan bir optimizasyon yÃ¶ntemidir.
###### RandomizedSearchCV belirli bir sayÄ±da rastgele seÃ§ilmiÅŸ hiperparametre kombinasyonunu test ederek sorunu Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±r.
###### Bu sayede arama sÃ¼resini kÄ±saltabilir ve daha hÄ±zlÄ± sonuÃ§lar elde edilmesine olanak tanÄ±r.
###### Ã–zellikle bÃ¼yÃ¼k veri kÃ¼meleri veya Ã§ok sayÄ±da hiperparametre kombinasyonu olan durumlarda kullanÄ±ÅŸlÄ±dÄ±r. 
###### Deneme sayÄ±sÄ±nÄ± belirleyerek (Ã¶rneÄŸin, n_iter=100), daha esnek ve hÄ±zlÄ± bir ÅŸekilde en iyi hiperparametrelerin bulunmasÄ±na yardÄ±mcÄ± olur.

![image](https://github.com/akay35/hiperparametre-optimizasyon-metodlari/blob/main/RandomizedSearchCV.png)

###### n_iter=100 ifadesi, RandomizedSearchCV'nin hiperparametre optimizasyonu sÄ±rasÄ±nda deneyeceÄŸi 100 farklÄ± kombinasyonu belirtmektedir. Bu, modelin hiperparametreleri iÃ§in rastgele seÃ§ilen 100 farklÄ± seti test edeceÄŸi anlamÄ±na gelir.
###### Hiperparametrelerin daÄŸÄ±lÄ±mlarÄ± (param_distributions) belirlenir. Ã–rneÄŸin, Ã¶ÄŸrenme hÄ±zÄ± (learning_rate), maksimum derinlik (max_depth), aÄŸaÃ§ sayÄ±sÄ± (n_estimators) gibi hiperparametreler iÃ§in belirli aralÄ±klar veya olasÄ±lÄ±k daÄŸÄ±lÄ±mlarÄ± tanÄ±mlanÄ±r.
###### RandomizedSearchCV, her bir hiperparametre iÃ§in belirtilen aralÄ±ktan veya daÄŸÄ±lÄ±mdan rastgele deÄŸerler seÃ§er. Bu seÃ§ilen deÄŸerler, modelin hiperparametre kombinasyonlarÄ±nÄ± oluÅŸturur.
###### n_iter=100 olduÄŸu iÃ§in, RandomizedSearchCV bu hiperparametrelerin 100 farklÄ± rastgele kombinasyonunu oluÅŸturur ve her birini test eder.
###### EÄŸer learning_rate iÃ§in 4 farklÄ± deÄŸer, max_depth iÃ§in 5 farklÄ± deÄŸer ve n_estimators iÃ§in 10 farklÄ± deÄŸer varsa, bu kombinasyonlar arasÄ±nda rastgele seÃ§imler yapÄ±lÄ±r ve toplamda 100 farklÄ± kombinasyon test edilir.

###### HÄ±zlÄ± olmasÄ±, yÃ¼ksek boyutlu veriler iÃ§in uygun olmasÄ± ve optimizasyon iÃ§in pratik olmasÄ± gibi avantajlarÄ±nÄ±n yanÄ±nda, tÃ¼m olasÄ± kombinasyonlarÄ± denemediÄŸi iÃ§in bazen en iyi hiperparametre setini kaÃ§Ä±rabilmesi ve rastgele olarak Ã§alÄ±ÅŸma yapmasÄ± dezavantajlarÄ± olarak sayÄ±labilir.

---

### 2. GridSearchCV
###### Scikit-learn kÃ¼tÃ¼phanesinde bulunan bu yÃ¶ntem, belirli hiperparametrelerin tÃ¼m olasÄ± kombinasyonlarÄ±nÄ± dener ve en iyi sonucu veren parametre setini bulur. 
###### "Grid" kelimesi, parametrelerin farklÄ± deÄŸerlerinin oluÅŸturduÄŸu bir Ä±zgaraya (grid) atÄ±fta bulunur, Ã§Ã¼nkÃ¼ her hiperparametre iÃ§in belirli bir dizi deÄŸer belirlenir ve bu deÄŸerlerin her bir kombinasyonu test edilir.

![image](https://github.com/akay35/hiperparametre-optimizasyon-metodlari/blob/main/GridSearchCV.png)

###### YukarÄ±daki resimdeki Ã¶rnekte GridSearchCV bu 4 x 12 x 5 x 10 = 2400  kombinasyonu sÄ±rasÄ±yla test eder.
###### Her parametre kombinasyonu iÃ§in model yeniden eÄŸitilir ve genellikle k-katlamalÄ± Ã§apraz doÄŸrulama (k-fold cross-validation) ile deÄŸerlendirilir. 
###### Ã‡apraz doÄŸrulama, modelin doÄŸruluÄŸunu daha gÃ¼venilir bir ÅŸekilde Ã¶lÃ§mek iÃ§in veri setini birkaÃ§ alt kÃ¼meye bÃ¶ler ve her alt kÃ¼mede modelin performansÄ±nÄ± test eder.

###### GridSearch tÃ¼m kombinasyonlarÄ± denerken daha kesin sonuÃ§lar sunar, RandomizedSearch ise geniÅŸ aralÄ±klar iÃ§in daha hÄ±zlÄ± ve pratiktir.

---

### 3. BayesSearchCV

###### Bu yÃ¶ntem, Ã¶zellikle hiperparametrelerin sayÄ±sÄ±nÄ±n Ã§ok fazla olduÄŸu durumlarda daha verimli ve hÄ±zlÄ± sonuÃ§lar almayÄ± saÄŸlar. 
###### BayesSearchCV, klasik yÃ¶ntemler (Ã¶rneÄŸin GridSearchCV veya RandomizedSearchCV) ile karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda daha az parametre setiyle daha iyi sonuÃ§lar elde etmeye Ã§alÄ±ÅŸÄ±r.

- Ä°lk baÅŸta, modelin hiperparametreleri iÃ§in rastgele bazÄ± kombinasyonlar seÃ§ilir ve bu kombinasyonlarÄ±n nasÄ±l performans gÃ¶sterdiÄŸi test edilir.
- SeÃ§ilen parametre kombinasyonlarÄ±nÄ±n baÅŸarÄ±sÄ± deÄŸerlendirilir ve bu sonuÃ§lar bir modelde kullanÄ±larak gelecekteki denemelere rehberlik eder.
- Ä°lk denemelerden elde edilen sonuÃ§lara dayanarak, BayesSearchCV daha iyi performans gÃ¶sterme olasÄ±lÄ±ÄŸÄ± olan yeni parametre kombinasyonlarÄ±nÄ± Ã¶nerir. Bu Ã¶neriler, bir acquisition function (kazanÃ§ fonksiyonu) kullanÄ±larak yapÄ±lÄ±r. Bu fonksiyon, hangi parametrelerin deneneceÄŸi konusunda bir strateji geliÅŸtirir.
- Ã–nerilen yeni parametre kombinasyonlarÄ± test edilir ve sonuÃ§lar modelin bir sonraki Ã¶neri iÃ§in daha da iyileÅŸtirilmesine yardÄ±mcÄ± olur.
- Bu iÅŸlem tekrar edilerek, modelin performansÄ± sÃ¼rekli olarak iyileÅŸtirilir. Yani, BayesSearchCV daha hÄ±zlÄ± ve verimli bir ÅŸekilde en iyi parametre kombinasyonlarÄ±nÄ± bulur.

![image](https://github.com/akay35/hiperparametre-optimizasyon-metodlari/blob/main/BayesSearchCV.png)

YukarÄ±daki Ã¶rnekte BayesSearchCV parametre ayarlamalarÄ±nÄ±n aÃ§Ä±klamalarÄ± aÅŸaÄŸÄ±daki gibidir:
- estimator: Hangi modelin optimizasyon yapÄ±lacaÄŸÄ± belirtilir. Burada lgbm_model (LightGBM sÄ±nÄ±flandÄ±rÄ±cÄ±) kullanÄ±lÄ±yor.
- search_spaces: Parametre arama alanlarÄ±nÄ± tanÄ±mlar. Yani, hangi parametrelerin hangi deÄŸer aralÄ±klarÄ±nda test edileceÄŸini belirleriz. Burada yukarÄ±da tanÄ±mladÄ±ÄŸÄ±mÄ±z param_grid kullanÄ±lmÄ±ÅŸtÄ±r.
- n_iter: Optimizasyon sÃ¼recinde kaÃ§ iterasyon yapÄ±lacaÄŸÄ±nÄ± belirtir. Burada 32 iterasyon yapÄ±lacak, yani toplamda 32 farklÄ± parametre kombinasyonunun test edileceÄŸini belirtir.
- cv: 5-fold Ã§apraz doÄŸrulama (cross-validation) kullanÄ±lÄ±r. Bu, modelin daha saÄŸlam sonuÃ§lar verebilmesi iÃ§in veriyi 5 eÅŸit parÃ§aya ayÄ±rÄ±p her bir parÃ§ayÄ± sÄ±rayla test ve eÄŸitim iÃ§in kullanmayÄ± saÄŸlar.
- scoring: Modelin baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek iÃ§in roc_auc (Receiver Operating Characteristic - Area Under Curve) metriÄŸi kullanÄ±lmÄ±ÅŸtÄ±r. Bu, sÄ±nÄ±flandÄ±rma problemleri iÃ§in yaygÄ±n bir baÅŸarÄ± Ã¶lÃ§Ã¼tÃ¼dÃ¼r.

---

### 4. HalvingGridSearchCV

HalvingGridSearchCV, GridSearchCV'nin geniÅŸletilmiÅŸ bir versiyonudur. GridSearchCV, verilen hiperparametre grid'inde (matrisinde) her kombinasyonu test ederek en iyi parametreyi bulmaya Ã§alÄ±ÅŸÄ±r. Ancak, bu Ã§ok sayÄ±da parametre ve model eÄŸitimi gerektirebilir ve iÅŸlem sÃ¼resi uzun olabilir. HalvingGridSearchCV, bu sÃ¼reci hÄ±zlandÄ±rmak iÃ§in daha verimli bir yÃ¶ntem sunar.

##### HalvingGridSearchCV'nin temel mantÄ±ÄŸÄ± ÅŸu ÅŸekildedir:
- Ä°lk olarak daha kÃ¼Ã§Ã¼k bir alt kÃ¼me (Daha kÃ¼Ã§Ã¼k veri setiyle) kullanÄ±larak parametrelerin doÄŸruluÄŸu hesaplanÄ±r.
- Ä°lk adÄ±mda iyi performans gÃ¶steren parametreler seÃ§ilir.
- YÃ¼ksek doÄŸruluk gÃ¶stermeyen parametreler, sonraki adÄ±mlarda deneme dÄ±ÅŸÄ± bÄ±rakÄ±lÄ±r.
- SeÃ§ilen parametrelerle model tekrar eÄŸitilir ancak bu kez daha bÃ¼yÃ¼k bir veri kÃ¼mesi kullanÄ±lÄ±r.
- SonuÃ§larÄ± sÄ±rasÄ±yla daraltmak: Her adÄ±mda, bir sonraki deneme iÃ§in yalnÄ±zca iyi performans gÃ¶steren parametreler kullanÄ±larak daha kÃ¼Ã§Ã¼k, ancak daha anlamlÄ± kombinasyonlar Ã¼zerinde Ã§alÄ±ÅŸÄ±lÄ±r.

##### HalvingGridSearchCV'nin Temel Parametreleri:
![image](https://github.com/akay35/hiperparametre-optimizasyon-metodlari/blob/main/HalvingGridSearchCV.png)

- estimator    : Hangi modelin kullanÄ±lacaÄŸÄ±nÄ± belirtir.
- param_grid   : Denenecek parametrelerin bir gridi.
- n_candidates : Ä°lk denemede kaÃ§ parametre kombinasyonunun test edileceÄŸi.
- factor       : Her adÄ±mda kaybeden parametrelerin ne kadar azaltÄ±lacaÄŸÄ±nÄ± belirtir (Ã¶rneÄŸin, 3, 4, 5 gibi). Bu, daha fazla parametreyi hÄ±zlÄ±ca elemeye yardÄ±mcÄ± olur.
- min_resources: Ä°lk denemede kullanÄ±lacak en kÃ¼Ã§Ã¼k Ã¶rnek sayÄ±sÄ±.
- n_jobs       : Paralel iÅŸleme sayÄ±sÄ±.

---

### 5. Evolutionary Algorithms

TPOT (Tree-based Pipeline Optimization Tool), evrimsel algoritmalarla otomatik makine Ã¶ÄŸrenimi (AutoML) saÄŸlayan bir Python kÃ¼tÃ¼phanesidir. TPOT, veriler Ã¼zerinde model oluÅŸturma sÃ¼recini otomatize eder. Bu, genetik algoritmalar kullanarak farklÄ± model yapÄ±larÄ±nÄ± (algoritmalar, hiperparametreler, veri iÅŸleme yÃ¶ntemleri vb.) deneyip optimize eder.

##### TPOT ve Evrimsel AlgoritmalarÄ±n Ã‡alÄ±ÅŸma Prensibi
TPOT, evrimsel algoritmalarla Ã§alÄ±ÅŸarak Ã§eÅŸitli model yapÄ±larÄ±nÄ± "evrimleÅŸtirir" ve en iyi performansÄ± gÃ¶steren model tÃ¼revini bulur. Temel olarak ÅŸu adÄ±mlarÄ± takip eder:

- BaÅŸlangÄ±Ã§ PopÃ¼lasyonu: TPOT, baÅŸlangÄ±Ã§ta farklÄ± makine Ã¶ÄŸrenimi modellerinin rastgele kombinasyonlarÄ±nÄ± iÃ§erir. Bu modeller, algoritmalarÄ±n ve hiperparametrelerin birleÅŸiminden oluÅŸur.
- Fitness (Uygunluk) Fonksiyonu: Her bireyin baÅŸarÄ±sÄ±nÄ± (fitness'Ä±nÄ±) Ã¶lÃ§mek iÃ§in genellikle modelin doÄŸruluk oranÄ±, f1 skoru gibi metrikler kullanÄ±lÄ±r. Fitness fonksiyonu, modelin baÅŸarÄ±sÄ±nÄ± deÄŸerlendiren Ã¶lÃ§Ã¼tleri tanÄ±mlar.
- SeÃ§im: Fitness deÄŸerlerine gÃ¶re, daha iyi olan bireyler seÃ§ilir. Bu, doÄŸal seleksiyon ilkesine benzer. En iyi modeller, bir sonraki nesilde daha fazla yer alÄ±r.
- Ã‡aprazlama (Crossover): SeÃ§ilen modellerin (bireylerin) parametreleri birbirleriyle "Ã§aprazlanarak" yeni bireyler (model kombinasyonlarÄ±) oluÅŸturulur. Bu adÄ±mda, genetik algoritmalarÄ±n Ã§aprazlama sÃ¼reÃ§lerine benzer ÅŸekilde, yeni bir nesil model yapÄ±landÄ±rÄ±lÄ±r.
- Mutasyon: Ã‡aprazlama sonrasÄ±, bazÄ± bireylerde rastgele deÄŸiÅŸiklikler (mutasyonlar) yapÄ±lÄ±r. Bu, yeni ve farklÄ± Ã§Ã¶zÃ¼m adaylarÄ±nÄ± keÅŸfetmek iÃ§in gereklidir. Mutasyon, model parametrelerinde kÃ¼Ã§Ã¼k deÄŸiÅŸiklikler yapar.
- Yeni Nesil ve Tekrar: Yeni nesil, Ã¶nceki nesilden daha iyi Ã§Ã¶zÃ¼mler sunduÄŸu sÃ¼rece evrimleÅŸir. Bu sÃ¼reÃ§, belirli bir sayÄ±da nesil geÃ§ene kadar veya belirli bir kriter saÄŸlanana kadar devam eder.
- SonuÃ§: TPOT, en iyi performans gÃ¶steren modeli ve parametre kombinasyonunu sunar. Bu model, doÄŸruluk, f1 skoru, recall gibi metriklere gÃ¶re deÄŸerlendirilmiÅŸ olur.

![image](https://github.com/akay35/hiperparametre-optimizasyon-metodlari/blob/main/evolutionary%20algorithms.png)

##### TPOT Parametreleri
- generations: TPOTâ€™in kaÃ§ nesil boyunca evrimleÅŸeceÄŸini belirler. YÃ¼ksek sayÄ±lar daha fazla hesaplama gÃ¼cÃ¼ gerektirir, ancak daha iyi sonuÃ§lar elde etme olasÄ±lÄ±ÄŸÄ± artÄ±rÄ±r.
- population_size: Her nesilde yer alacak model sayÄ±sÄ±nÄ± belirtir. Daha fazla model daha fazla keÅŸif yapmanÄ±zÄ± saÄŸlar.
- random_state: SonuÃ§larÄ±n tekrar edilebilirliÄŸini saÄŸlar.
- scoring: Hangi skor metriÄŸi ile modeli deÄŸerlendireceÄŸini belirler (Ã¶rneÄŸin, doÄŸruluk, f1 skoru vb.).

TPOT, Ã§ok sayÄ±da model ve parametreyi test ettiÄŸi iÃ§in yÃ¼ksek hesaplama gÃ¼cÃ¼ gerektirir, bÃ¼yÃ¼k veri setleri veya Ã§ok sayÄ±da nesil ile iÅŸlem yapÄ±ldÄ±ÄŸÄ±nda, iÅŸlem sÃ¼resi oldukÃ§a uzun olabilir.

---

### 6. Tree-structured Parzen Estimator (TPE)
###### Hiperparametreleri sistematik bir ÅŸekilde aramak yerine, olasÄ±lÄ±ksal bir model kullanarak en iyi hiperparametreleri tahmin eder. 
###### Bu yÃ¶ntem, Bayesian optimization Ã§erÃ§evesinde Ã§alÄ±ÅŸÄ±r ve hiperparametre arama iÅŸlemini daha etkili ve verimli hale getirir.
###### TPE, Ã¶zellikle Hyperopt kÃ¼tÃ¼phanesinde bir optimizasyon algoritmasÄ± olarak yaygÄ±nca kullanÄ±lÄ±r. 

##### TPE Ã‡alÄ±ÅŸma Prensibi
- Hiperparametre AlanÄ±nÄ± TanÄ±mlama: Hiperparametreler iÃ§in bir arama alanÄ± (search space) belirlenir. Bu alan, sÃ¼rekli (Ã¶rneÄŸin Ã¶ÄŸrenme oranÄ±), ayrÄ±k (Ã¶rneÄŸin katman sayÄ±sÄ±), veya kategorik (Ã¶rneÄŸin aktivasyon fonksiyonu) deÄŸerlerden oluÅŸabilir.
- Ä°lk Rastgele Denemeler: TPE, baÅŸlangÄ±Ã§ta hiperparametre kombinasyonlarÄ±nÄ± rastgele seÃ§er ve bu kombinasyonlarÄ± deÄŸerlendirir (Ã¶rneÄŸin, Ã§apraz doÄŸrulama sonucu ile). Bu denemeler, olasÄ±lÄ±k daÄŸÄ±lÄ±mlarÄ±nÄ± oluÅŸturmak iÃ§in veri saÄŸlar.
- Performans DaÄŸÄ±lÄ±mlarÄ±nÄ± Modelleme: Hedef performans (Ã¶rneÄŸin, doÄŸruluk) iÃ§in bir eÅŸik deÄŸeri y* belirlenir. Bu deÄŸer, genellikle tÃ¼m hedef deÄŸerlerin belirli bir yÃ¼zdelik dilimidir (Ã¶rneÄŸin, ilk %20'lik dilim).
- Daha sonra, hiperparametreler iki gruba ayrÄ±lÄ±r:

ğ‘™ (ğ‘¥): ğ‘¦>ğ‘¦âˆ— (daha kÃ¶tÃ¼ performans)
ğ‘”(ğ‘¥): ğ‘¦â‰¤ğ‘¦âˆ— (daha iyi performans)

- Yeni Hiperparametre Ã–nerileri: TPE, daha Ã¶nceki denemelerde yÃ¼ksek performans gÃ¶stermiÅŸ hiperparametre deÄŸerlerinin etrafÄ±nda yoÄŸunlaÅŸan yeni hiperparametreler Ã¶nerir. Bu, ğ‘”(ğ‘¥) / ğ‘™(ğ‘¥) oranÄ±nÄ± maksimize edecek ÅŸekilde yapÄ±lÄ±r.
- Deneme ve GÃ¼ncelleme: Ã–nerilen hiperparametreler denendikten sonra sonuÃ§lar kaydedilir ve olasÄ±lÄ±k modelleri gÃ¼ncellenir. Bu iÅŸlem, belirlenen bir iterasyon veya zaman sÄ±nÄ±rÄ±na kadar devam eder.

##### Tree-structured Parzen Estimator (TPE) Parametre AyarlamalarÄ±
##### 1. Hiperparametre Arama AlanÄ± (Search Space)
- hp.choice(label, options)
AyrÄ±k (discrete) deÄŸerler arasÄ±ndan seÃ§im yapar. Ã–rneÄŸin, karar aÄŸacÄ±nÄ±n criterion parametresi ['gini', 'entropy'] olabilir.
###### 'criterion': hp.choice('criterion', ['gini', 'entropy'])

- hp.uniform(label, low, high)
Belirtilen alt ve Ã¼st sÄ±nÄ±r arasÄ±nda sÃ¼rekli bir aralÄ±kta rastgele deÄŸer seÃ§er. Ã–rneÄŸin, Ã¶ÄŸrenme oranÄ± (learning_rate) genellikle bu ÅŸekilde tanÄ±mlanÄ±r.
###### 'learning_rate': hp.uniform('learning_rate', 0.01, 0.3)

- hp.quniform(label, low, high, q)
Belirtilen sÃ¼rekli aralÄ±kta sabit artÄ±ÅŸlarla deÄŸer seÃ§er. Ã–rneÄŸin, n_estimators iÃ§in tam sayÄ±lar gereklidir, bu yÃ¼zden q ile adÄ±m bÃ¼yÃ¼klÃ¼ÄŸÃ¼ belirlenir.
###### 'n_estimators': hp.quniform('n_estimators', 10, 200, 10)

- hp.loguniform(label, low, high)
Logaritmik Ã¶lÃ§ekli sÃ¼rekli bir aralÄ±kta rastgele deÄŸer seÃ§er. Ã–ÄŸrenme oranÄ± gibi parametrelerde Ã§ok kÃ¼Ã§Ã¼k deÄŸerler Ã¶nemli olabilir.
###### 'learning_rate': hp.loguniform('learning_rate', -3, 0)  # 0.001 ile 1 arasÄ±nda

- hp.randint(label, upper)
Belirtilen Ã¼st sÄ±nÄ±ra kadar tam sayÄ± deÄŸerler seÃ§er.
###### 'max_depth': hp.randint('max_depth', 20)

##### 2. AmaÃ§ Fonksiyonu (Objective Function)
AmaÃ§ fonksiyonu, TPE'nin optimize edeceÄŸi performans Ã¶lÃ§Ã¼tÃ¼nÃ¼ tanÄ±mlar. Bu, genellikle modelin hiperparametreler iÃ§in doÄŸrulama setindeki performansÄ±nÄ± dÃ¶ndÃ¼ren bir fonksiyondur.

AmaÃ§: Performans metriÄŸini en aza indirmek veya en Ã¼st dÃ¼zeye Ã§Ä±karmak.

Negatif metrikler: Hyperopt, optimize edilen deÄŸeri minimum yapmayÄ± hedefler. Pozitif bir metriÄŸi en iyi yapÄ±lmasÄ± isteniliyorsa (Ã¶rneÄŸin accuracy), negatifini dÃ¶ndÃ¼rÃ¼lmelidir:
###### return -accuracy
- Ã–rnek:
###### def objective(params):
######     model = RandomForestClassifier(
######         max_depth=params['max_depth'],
######         n_estimators=int(params['n_estimators']),
######         criterion=params['criterion'])
######     score = cross_val_score(model, X, y, cv=3).mean()
######     return -score

##### 3. fmin Fonksiyonu

Bu fonksiyon, TPE'nin temel optimizasyon fonksiyonudur ve ÅŸu parametrelerle Ã§alÄ±ÅŸÄ±r:
- fn (Objective Function): Optimize edilmek istenen amaÃ§ fonksiyonunu belirtir.
- space (Search Space): Hiperparametre arama alanÄ±nÄ± belirtir.
- algo (Algorithm): KullanÄ±lacak optimizasyon algoritmasÄ±nÄ± belirtir. TPE iÃ§in:
###### algo=tpe.suggest
- max_evals (Maksimum Deneme SayÄ±sÄ±): KaÃ§ farklÄ± hiperparametre kombinasyonu deneneceÄŸini belirtir.
###### max_evals=50  # 50 farklÄ± kombinasyon denenecek
- trials (Deneme GeÃ§miÅŸi): Hangi denemelerin yapÄ±ldÄ±ÄŸÄ±nÄ± ve sonuÃ§larÄ±nÄ± kaydeden bir objedir. SonuÃ§larÄ± gÃ¶rselleÅŸtirmek veya analiz etmek iÃ§in kullanÄ±labilir.
trials = Trials()


#### Ã–rnek Ã‡alÄ±ÅŸma 
![image](https://github.com/akay35/hiperparametre-optimizasyon-metodlari/blob/main/tpe1.png)
1. Hedef Fonksiyon (Objective Function)
Hedef fonksiyon, optimizasyon algoritmasÄ±nÄ±n deÄŸerlendireceÄŸi parametrelerin model Ã¼zerindeki etkisini Ã¶lÃ§er.
###### Parametrelerin hazÄ±rlanmasÄ±:
params: TPE'nin Ã¶nerdiÄŸi parametreler model formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor. Ã–rneÄŸin:
- learning_rate: Modelin Ã¶ÄŸrenme hÄ±zÄ±.
- n_estimators: AÄŸaÃ§ sayÄ±sÄ± (tam sayÄ± olarak verilmesi gerektiÄŸi iÃ§in int() ile Ã§evrilir).
- colsample_bytree: Ã–zelliklerin Ã¶rnekleme oranÄ±.
- num_leaves: Modeldeki yaprak sayÄ±sÄ±.
- max_depth: AÄŸacÄ±n maksimum derinliÄŸi.
Model oluÅŸturma:
lgb.LGBMClassifier: LightGBM modeli, verilen parametrelerle oluÅŸturuluyor.
Modelin deÄŸerlendirilmesi:
cross_val_score: 5 katlÄ± Ã§apraz doÄŸrulama kullanarak modelin performansÄ± hesaplanÄ±r.
scoring='roc_auc': Performans Ã¶lÃ§Ã¼tÃ¼ olarak ROC AUC (Receiver Operating Characteristic - Area Under Curve) kullanÄ±lÄ±r.
###### SonuÃ§ dÃ¶ndÃ¼rme:
loss: Negatif ROC AUC deÄŸeri dÃ¶ndÃ¼rÃ¼lÃ¼r. Ã‡Ã¼nkÃ¼ Hyperopt, bu deÄŸeri minimum yapmayÄ± hedefler. Bu nedenle performansÄ± artÄ±rmak iÃ§in negatif bir deÄŸer kullanÄ±lÄ±r.
status: Fonksiyonun baÅŸarÄ± durumu.

2. Parametre Arama AlanÄ± (Search Space)
Hiperparametrelerin deÄŸer aralÄ±klarÄ± bu alanda tanÄ±mlanÄ±r:
- learning_rate (hp.uniform):
SÃ¼rekli bir deÄŸer alÄ±r.
AralÄ±k: 0.005 ile 0.1 (daha dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme hÄ±zlarÄ± daha hassas Ã¶ÄŸrenme saÄŸlar).

- n_estimators (hp.quniform):
Belirli adÄ±mlarla tam sayÄ± deÄŸer alÄ±r.
AralÄ±k: 10 ile 350 arasÄ±nda, 5 adÄ±mlarla.

- colsample_bytree (hp.uniform):
Bir aÄŸacÄ±n eÄŸitiminde kullanÄ±lacak Ã¶zelliklerin oranÄ± (0.3 ile 1 arasÄ±nda).
DÃ¼ÅŸÃ¼k deÄŸerler fazla Ã¶zellik seÃ§iminden kaÃ§Ä±nÄ±r.

- num_leaves (hp.quniform):
Modelin yaprak sayÄ±sÄ±nÄ± kontrol eder (overfittingâ€™i kontrol etmek iÃ§in Ã¶nemli).
AralÄ±k: 5 ile 35 arasÄ±nda.

- max_depth (hp.quniform):
AÄŸacÄ±n maksimum derinliÄŸini kontrol eder.
AralÄ±k: 3 ile 10.

![image](https://github.com/akay35/hiperparametre-optimizasyon-metodlari/blob/main/tpe2.png)

3. Optimizasyon SÃ¼reci
Bu bÃ¶lÃ¼mde, TPE algoritmasÄ± ile en iyi parametre kombinasyonu aranÄ±r:
- Trials():
TÃ¼m denemeleri ve sonuÃ§larÄ±nÄ± kaydeder.
Performans analizinde kullanÄ±labilir.
trials nesnesinin fonksiyonun dÄ±ÅŸÄ±nda tanÄ±mlanmasÄ±nÄ±n sebebi, TPE algoritmasÄ±nÄ±n optimizasyon sÄ±rasÄ±nda yaptÄ±ÄŸÄ± her denemeyi (parametre kombinasyonlarÄ±nÄ± ve bunlarÄ±n sonuÃ§larÄ±nÄ±) kaydetmek ve bu bilgilere daha sonra eriÅŸilebilmeyi saÄŸlamaktÄ±r.
trials nesnesi sayesinde tÃ¼m deneme kayÄ±tlarÄ±na fonksiyon dÄ±ÅŸÄ±nda aÅŸaÄŸÄ±daki kodlar ile eriÅŸilebilir.
###### print(trials.results)  # Denemelerin sonuÃ§larÄ±nÄ± gÃ¶sterir
###### print(trials.best_trial)  # En iyi sonucu dÃ¶ndÃ¼ren deneme

- fmin Fonksiyonu:
###### fn=objective: Optimize edilecek hedef fonksiyon.
###### space=param_space: Hiperparametre arama alanÄ±.
###### algo=tpe.suggest: TPE algoritmasÄ± kullanÄ±lacak.
###### max_evals=50: 50 farklÄ± parametre kombinasyonu denenecek.
SonuÃ§lar:
fmin, en iyi hiperparametre kombinasyonunu dÃ¶ndÃ¼rÃ¼r ve bu kombinasyon best_params deÄŸiÅŸkenine kaydedilir.

---

### Genel DeÄŸerlendirme ve Hangi Durumlarda Hangi YÃ¶ntem Tercih Edilmeli?
![image](https://github.com/akay35/hiperparametre-optimizasyon-metodlari/blob/main/METR%C4%B0KLER%C4%B0N%20DE%C4%9EERLEND%C4%B0R%C4%B0LMES%C4%B0.png)

#### 1. TPOTClassifier
Genel Performans: TPOTClassifier, doÄŸruluk (accuracy) aÃ§Ä±sÄ±ndan en yÃ¼ksek sonucu veriyor (0.819). Ancak, diÄŸer metriklerde (F1-Score: 0.625, ROC AUC: 0.739) daha dÃ¼ÅŸÃ¼k performans sergiliyor. Yani, model genel olarak doÄŸru tahminler yapÄ±yor ama pozitif sÄ±nÄ±fÄ± ve dengesiz sÄ±nÄ±f problemlerini yeterince iyi ayÄ±rt edemiyor.

- Ne zaman tercih edilmeli?
EÄŸer doÄŸruluk Ã¶nemliyse, yani genel doÄŸruluÄŸu artÄ±rmak istiyorsanÄ±z, TPOTClassifier iyi bir seÃ§im olabilir. Bu, Ã¶rneÄŸin, sÄ±nÄ±flarÄ±n oldukÃ§a dengeli olduÄŸu ve tÃ¼m sÄ±nÄ±flarÄ±n doÄŸru tahmin edilmesinin kritik olmadÄ±ÄŸÄ± durumlarda geÃ§erli olabilir.
Fakat, sÄ±nÄ±flarÄ±n dengesiz olduÄŸu bir durumdaysanÄ±z, TPOTClassifier'in sÄ±nÄ±flar arasÄ±ndaki farklarÄ± yeterince iyi ayÄ±rt edemeyebileceÄŸini unutmayÄ±n.

#### 2. TPE (Tree-structured Parzen Estimator) ve BayesSearchCV
Genel Performans: TPE ve BayesSearchCV, ROC AUC (0.846) ve recall (0.806) gibi metriklerde en yÃ¼ksek sonuÃ§larÄ± almÄ±ÅŸ. ROC AUC, modelin pozitif ve negatif sÄ±nÄ±flarÄ± ayÄ±rt etme yeteneÄŸini Ã¶lÃ§erken, recall ise pozitif sÄ±nÄ±fÄ± doÄŸru tahmin etme yeteneÄŸini gÃ¶steriyor. Yani bu iki yÃ¶ntem, pozitif sÄ±nÄ±fÄ±n doÄŸru tahmin edilmesi ve sÄ±nÄ±f ayÄ±rt edebilme kabiliyetinin gÃ¼Ã§lÃ¼ olduÄŸu durumlarÄ± iÅŸaret ediyor.

Ne zaman tercih edilmeli?
EÄŸer modelin pozitif sÄ±nÄ±fÄ± doÄŸru tahmin etme yeteneÄŸi Ã¶nemliyse, yani yalan negatiflerin (false negatives) Ã¶nemli olduÄŸu bir problem Ã§Ã¶zÃ¼yorsanÄ±z (Ã¶rneÄŸin, hastalÄ±k tespiti veya spam e-postalarÄ±nÄ±n tespiti gibi), TPE ve BayesSearchCV daha iyi performans gÃ¶sterecektir.
AyrÄ±ca, dengesiz sÄ±nÄ±f daÄŸÄ±lÄ±mÄ± olan veri setlerinde de bu yÃ¶ntemlerin performansÄ± daha gÃ¼Ã§lÃ¼ olacaktÄ±r Ã§Ã¼nkÃ¼ ROC AUC ve recall, modelin her iki sÄ±nÄ±fÄ± da doÄŸru ÅŸekilde ayÄ±rÄ±p ayÄ±rmadÄ±ÄŸÄ±nÄ± dikkate alÄ±r.

#### 3. HalvingGridSearchCV
Genel Performans: HalvingGridSearchCV, F1-Score'da en yÃ¼ksek (0.631) skoru almÄ±ÅŸ. Bu, modelin hem pozitif hem de negatif sÄ±nÄ±flarÄ± dengeli bir ÅŸekilde tahmin ettiÄŸini gÃ¶sterir. YÃ¼ksek F1-Score, yanlÄ±ÅŸ pozitif ve yanlÄ±ÅŸ negatif hatalarÄ±nÄ±n minimize edildiÄŸini gÃ¶sterir.

Ne zaman tercih edilmeli?
EÄŸer dengeleme (precision-recall trade-off) Ã¶nem taÅŸÄ±yorsa ve her iki sÄ±nÄ±fÄ±n doÄŸru tahmin edilmesi isteniyorsa, HalvingGridSearchCV iyi bir tercihtir. Ã–zellikle dengesiz sÄ±nÄ±f problemleriyle Ã§alÄ±ÅŸÄ±rken her iki sÄ±nÄ±fÄ± da dengeli bir ÅŸekilde tahmin edebilmek iÃ§in F1-Score Ã¶nemli bir metriktir.
Bu yÃ¶ntem, karmaÅŸÄ±k hiperparametre arama alanlarÄ±na sahip ve bÃ¼yÃ¼k veri setleri Ã¼zerinde Ã§alÄ±ÅŸan modeller iÃ§in de oldukÃ§a etkili olabilir Ã§Ã¼nkÃ¼ grid search algoritmasÄ±nÄ±n daha hÄ±zlÄ± bir ÅŸekilde Ã§Ã¶zÃ¼lmesini saÄŸlar.

#### 4. GridSearchCV ve RandomSearchCV
Genel Performans: GridSearchCV ve RandomSearchCV, genel olarak dengeyi koruyan metrikler sunuyorlar, ancak ROC AUC ve recall gibi metriklerde diÄŸer yÃ¶ntemlerin gerisinde kalÄ±yorlar.

Ne zaman tercih edilmeli?
EÄŸer modelin parametre optimizasyonu yapÄ±lÄ±rken, hÄ±zlÄ± bir baÅŸlangÄ±Ã§ ve deneysel esneklik isteniyorsa bu yÃ¶ntemler tercih edilebilir. Ã–zellikle daha kÃ¼Ã§Ã¼k veri setlerinde ve daha az karmaÅŸÄ±k modellerde GridSearchCV ve RandomSearchCV iyi sonuÃ§lar verebilir.
Ancak bÃ¼yÃ¼k ve dengesiz veri setlerinde ya da Ã§ok daha yÃ¼ksek metrik performansÄ± isteyen bir durumda, TPE veya BayesSearchCV gibi yÃ¶ntemler daha uygun olacaktÄ±r.

![image](https://github.com/akay35/hiperparametre-optimizasyon-metodlari/blob/main/genel%20de%C4%9Ferlendirme.png)


